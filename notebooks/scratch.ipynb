{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_process import DataReg\n",
    "import polars as pl\n",
    "import requests\n",
    "import bambi as bmb\n",
    "import geopandas as gpd\n",
    "from pysal.lib import weights\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from pysal.lib import cg as geometry\n",
    "import causalpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "dr = DataReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qcew = dr.base_data().with_columns(\n",
    "    treatment=pl.when(pl.col(\"year\") >= 2023).then(True).otherwise(False)\n",
    ")\n",
    "df_dp03 = dr.pull_dp03()\n",
    "df_dp03 = df_dp03.with_columns(qtr=1)\n",
    "pr_zips = gpd.GeoDataFrame(dr.make_spatial_table().df())\n",
    "pr_zips[\"geometry\"] = pr_zips[\"geometry\"].apply(wkt.loads)\n",
    "pr_zips = pr_zips.set_geometry(\"geometry\")\n",
    "pr_zips[\"zipcode\"] = pr_zips[\"zipcode\"].astype(str)\n",
    "\n",
    "df = df_qcew.join(df_dp03, on=[\"zipcode\",\"year\", \"qtr\"], how=\"left\")\n",
    "df = pr_zips.join(\n",
    "    df.to_pandas().set_index(\"zipcode\"), on=\"zipcode\", how=\"inner\", validate=\"1:m\"\n",
    "        ).reset_index(drop=True)\n",
    "df = df[df[\"year\"] >= 2012].sort_values(by=[\"zipcode\", \"year\",\"qtr\"]).reset_index(drop=True)\n",
    "pr_zips.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\"inc_less_10k\", \"inc_10k_15k\", \"inc_15k_25k\", \"inc_25k_35k\", \"inc_35k_50k\", \"inc_50k_75k\", \"inc_75k_100k\", \"inc_100k_150k\", \"inc_150k_200k\", \"inc_more_200k\"]\n",
    "\n",
    "for col in params:\n",
    "    df[col] = df[col].interpolate(method=\"cubic\")\n",
    "df = df.sort_values(by=[\"year\",\"qtr\",\"zipcode\"]).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"year\"] >= 2012].sort_values(by=[\"year\",\"qtr\",\"zipcode\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weights.distance.DistanceBand.from_dataframe(df[(df[\"year\"]== 2012) & (df[\"qtr\"]== 1)], 1609.344 * 20, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatial_lag(df, w, column):\n",
    "    # Reshape y to match the number of rows in the dataframe\n",
    "    y = df[column].values.reshape(-1, 1)\n",
    "    \n",
    "    # Apply spatial lag\n",
    "    spatial_lag = weights.lag_spatial(w, y)\n",
    "    \n",
    "    return spatial_lag\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "spatial_lag_results = []\n",
    "\n",
    "# Assuming `df` has 'year' and 'quarter' columns for grouping\n",
    "for year in range(2012,2019):\n",
    "    for qtr in range(1,5):\n",
    "        group_df = df[(df[\"year\"]== year) & (df[\"qtr\"]== qtr)].reset_index(drop=True)\n",
    "        spatial_lag = calculate_spatial_lag(group_df, w, 'total_employment')\n",
    "    \n",
    "    # Add the spatial lag results back to the group dataframe\n",
    "    group_df['w_employment'] = spatial_lag.flatten()  # Flatten to make it 1D for the column\n",
    "    \n",
    "    # Append the group to the results list\n",
    "    spatial_lag_results.append(group_df)\n",
    "\n",
    "# Concatenate all the results back together\n",
    "reg = pd.concat(spatial_lag_results)\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[(df[\"year\"]== 2012) & (df[\"qtr\"]== 1)].reset_index(drop=True)\n",
    "y = test[\"total_employment\"].values.reshape(-1,1)\n",
    "w = weights.contiguity.Queen.from_dataframe(df)\n",
    "# w.transform = 'r'\n",
    "reg = test\n",
    "reg[\"w_emplyment\"] = weights.lag_spatial(w,y) \n",
    "# reg\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `reg` is your DataFrame and you want to set the 'year' column as a datetime index\n",
    "data = reg.copy()\n",
    "data = data.drop(\"geometry\", axis=1)\n",
    "# data = data.drop(\"sector\", axis=1)\n",
    "# data = data.drop(\"treatment\", axis=1)\n",
    "data['date'] = data['year'] #* 10 + data['qtr']\n",
    "income_columns = [\n",
    "    'inc_25k_35k', 'inc_35k_50k', 'inc_50k_75k',\n",
    "    'inc_75k_100k', 'inc_100k_150k', 'inc_150k_200k',\n",
    "    'inc_more_200k'\n",
    "]\n",
    "\n",
    "# Step 1: Sort the DataFrame\n",
    "data = data.sort_values(by=['zipcode', 'zipcode', 'qtr'])\n",
    "\n",
    "# Step 2: Interpolate each column by zip group\n",
    "data[income_columns] = data.groupby('zipcode')[income_columns].transform(\n",
    "    lambda group: group.interpolate(method='linear', limit_direction='both')\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bmb.Model(\n",
    "    \"total_employment ~ k_index + date + w_employment\",\n",
    "    data, dropna=True\n",
    ")\n",
    "results = model.fit(target_accept=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = bmb.Model(\"total_employment ~ k_index + date + (1 + k_index|zipcode) + w_emplyment + inc_less_10k + inc_10k_15k + inc_15k_25k + inc_25k_35k + inc_35k_50k +  inc_50k_75k + inc_75k_100k + inc_100k_150k + inc_150k_200k\", data, dropna=True)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_priors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posteriors\n",
    "az.plot_trace(\n",
    "    results,\n",
    "    compact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = az.summary(results)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(results, combined=True, hdi_prob=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_extract = [\n",
    "        'inc_25k_35k', 'inc_35k_50k', 'inc_50k_75k',\n",
    "    'inc_75k_100k', 'inc_100k_150k', 'inc_150k_200k',\n",
    "    \"Intercept\",\n",
    "    \"date\",\n",
    "    \"k_index\",\n",
    "    \"sigma\",\n",
    "    \"w_emplyment\"\n",
    "]\n",
    "\n",
    "# Extract rows by index\n",
    "res.loc[rows_to_extract]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
