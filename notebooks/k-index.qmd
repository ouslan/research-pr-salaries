---
title: "Agriculture processing"
format:
  html:
    code-fold: true
jupyter: python3
---

```{python}
import os
os.chdir("..")
```

```{python}
import duckdb
import polars as pl
import geopandas as gpd
import altair as alt
import ibis
import libpysal
from pysal.lib import weights
import spreg
from src.data.data_process import DataReg
ibis.options.interactive = True
dr = DataReg()
```

```{python}
conn = duckdb.connect("data.ddb")
init_df = conn.sql("SELECT year,qtr,phys_addr_5_zip,first_month_employment,total_wages,second_month_employment,third_month_employment,naics_code FROM qcewtable").pl()
```

```{python}
df_qcew = init_df
df_qcew = df_qcew.rename({"phys_addr_5_zip":"zipcode"})
df_qcew = df_qcew.filter((pl.col("zipcode") != "") & (pl.col("naics_code") != ""))

df_qcew = df_qcew.with_columns(
    first_month_employment=pl.col("first_month_employment").fill_null(strategy="zero"),
    second_month_employment=pl.col("second_month_employment").fill_null(strategy="zero"),
    third_month_employment=pl.col("third_month_employment").fill_null(strategy="zero"),
    total_wages= pl.col("total_wages").fill_null(strategy="zero")
    )
df_qcew = df_qcew.with_columns(
            total_employment=(
                pl.col("first_month_employment") 
                + pl.col("second_month_employment")
                + pl.col("third_month_employment")
            ) / 3
        )
df_qcew = df_qcew.filter((pl.col("total_employment") != 0) & (pl.col("total_wages") != 0) )
df_qcew = df_qcew.with_columns(
    wages_employee=pl.col("total_wages") / pl.col("total_employment"),
    sector=pl.col("naics_code").str.slice(0,2)
)
df_qcew = df_qcew.group_by(["year","sector","zipcode"]).agg(
    mw_industry=pl.col("wages_employee").mean(),
    total_employment=pl.col("total_employment").sum()
)
df_qcew = df_qcew.with_columns(
        min_wage=pl.when((pl.col("year") >= 2002) & (pl.col("year") < 2010)).then(5.15 * 65 * 8)
        .when((pl.col("year") >= 2010) & (pl.col("year") < 2023)).then(7.25 * 65 * 8)
        .when(pl.col("year") == 2023).then(8.5 * 65 * 8)
        .when(pl.col("year") == 2024).then(10.5 * 65 * 8)
        .otherwise(-1)
    )
df_qcew = df_qcew.with_columns(k_index=pl.col("min_wage") / pl.col("mw_industry"))
df_qcew
```

```{python}
gdf = gpd.read_file("data/external/zip_shape.zip")
gdf = gdf[gdf["ZCTA5CE20"].str.startswith("00")].rename(columns={"ZCTA5CE20":"zipcode"}).reset_index()
```

```{python}
gdf = gdf[["zipcode","geometry"]]
gdf["zipcode"] = gdf["zipcode"].str.strip()
```


```{python}
tmp = df_qcew.to_pandas()
master_df = tmp.join(gdf.set_index("zipcode"), on="zipcode", how="inner", validate="m:1").reset_index()
master_df = gpd.GeoDataFrame(data=master_df, geometry=master_df["geometry"])
tmp = master_df[(master_df["year"] == 2024)]
```

```{python}
alt.Chart(tmp).mark_geoshape().encode(
    color=alt.Color("k_index:Q").scale(scheme='viridis')
).transform_lookup(
    lookup='zipcode',
    from_=alt.LookupData(tmp, 'zipcode', ['k_index'])
).project(
    type='mercator'
).properties(
    width="container",
)
# tmp.plot("k_index")
```

```{python}
chart = alt.Chart(tmp).mark_geoshape().encode(
    shape='geo:G',
    color=alt.Color("k_index:Q", scale=alt.Scale(scheme='viridis', domain=[0, 1])),
    tooltip=['zipcode:N', 'k_index:Q'],
    facet=alt.Facet('sector:Q', columns=5),
).transform_lookup(
    lookup='zipcode',
    from_=alt.LookupData(data=tmp, key="zipcode"),
    as_='geo'
).project(
    type='mercator'
)
chart.save('chart_year.png', ppi=200)
```


```{python}
tmp.pivot(index="zipcode", columns="sector", values="k_index")
```


```{python}
gdf = master_df[(master_df["sector"] == "31")]
gdf = gdf.set_crs('EPSG:4326', allow_override=True)
gdf = gdf.to_crs(epsg=32619)
gdf["centroid"] = gdf.centroid
# gdf = gdf.drop(columns=["geometry"])
# gdf = gpd.GeoDataFrame(data=gdf, geometry=gdf["centroid"])
gdf = gdf.sort_values(by=["year", "zipcode"]).reset_index(drop=True)

# Count the unique year-month combinations for each zipcode
common_zipcodes = gdf.groupby('zipcode')['year'].nunique()

# Find zip codes that appear in all year-month combinations
num_year_month_combinations = len(gdf['year'].drop_duplicates())  # Total distinct year-month combinations
common_zipcodes = common_zipcodes[common_zipcodes == num_year_month_combinations].index

# Filter the original DataFrame to show only those zip codes common across all year-month combinations
df_filtered = gdf[gdf['zipcode'].isin(common_zipcodes)]
df_filtered.plot()
```

```{python}
w = weights.distance.DistanceBand.from_dataframe(
    df_filtered[(df_filtered["year"] == 2024)], 80467
)
```

```{python}
x = df_filtered["k_index"].values.reshape(-1,1)
y = df_filtered["total_employment"].values.reshape(-1,1)
fe_lag = spreg.Panel_FE_Lag(
    y=y, 
    x=y, 
    w=w, 
    name_y=["employment"], 
    name_x=["k_index"]
)
print(fe_lag.summary)
# gdf[(gdf["year"] == 2021) & ((gdf["qtr"] == 1))].count()
# weight_df["zipcode"].unique().tolist()
```

```{python}

```
